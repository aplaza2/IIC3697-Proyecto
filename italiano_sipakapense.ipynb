{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96PapqzwAUkB"
   },
   "source": [
    "# Experimentos de Traducci√≥n Italiano -> Sipakapense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24058,
     "status": "ok",
     "timestamp": 1751914490002,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "t_FHD9kw266t",
    "outputId": "b8228647-62d1-414e-94cd-10b42e8b06f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1751915065697,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "yheiPHx8YN0m"
   },
   "outputs": [],
   "source": [
    "lang = \"it\"\n",
    "n_epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5rb6MT0A5mD"
   },
   "source": [
    "## Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1751914499219,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "yFaCwcFLx9HV"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 113194,
     "status": "ok",
     "timestamp": 1751914612411,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "Hg_qHsB95EzQ"
   },
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 56712,
     "status": "ok",
     "timestamp": 1751914669127,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "NF14LcemARSd"
   },
   "outputs": [],
   "source": [
    "!pip install -U accelerate peft transformers sentencepiece datasets\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install nltk\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 30557,
     "status": "ok",
     "timestamp": 1751914699688,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "7-HRnAKmA8LR"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x8Nds_8Y1Mm"
   },
   "source": [
    "## Datasets\n",
    "!REQUIERE SUBIR LOS ARCHIVOS DEL DATASET SINTETICO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smVHNrAeY5ck"
   },
   "source": [
    "Dataset se puede encontrar en el [siguiente enlace](https://github.com/transducens/mayanv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1540,
     "status": "ok",
     "timestamp": 1751914867862,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "F1ViYHauY4v3",
    "outputId": "7402ab5e-b046-4d05-a852-e7bc1ae9daab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mayanv'...\n",
      "remote: Enumerating objects: 177, done.\u001b[K\n",
      "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
      "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
      "remote: Total 177 (delta 22), reused 157 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (177/177), 1.35 MiB | 10.05 MiB/s, done.\n",
      "Resolving deltas: 100% (22/22), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/transducens/mayanv.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1751915109261,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "GLanJNSNRtt2",
    "outputId": "03600d39-52a8-4677-b16e-ce14873db1b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'IIC3697-Proyecto'...\n",
      "remote: Enumerating objects: 105, done.\u001b[K\n",
      "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 105 (delta 52), reused 74 (delta 29), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (105/105), 420.63 KiB | 8.58 MiB/s, done.\n",
      "Resolving deltas: 100% (52/52), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/aplaza2/IIC3697-Proyecto.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1751914995227,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "ghoF4-noMjaC"
   },
   "outputs": [],
   "source": [
    "def load_lines(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def generate_dataset(language, train_folder=\"train\", test_folder=\"test\", base_path=\"mayanv/MayanV\"):\n",
    "    # Rutas\n",
    "    train_lang_path = f\"{base_path}/{language}/{train_folder}/data.{language}\"\n",
    "    test_lang_path = f\"{base_path}/{language}/{test_folder}/data.{language}\"\n",
    "\n",
    "    train_es_path = f\"{base_path}/{language}/{train_folder}/data.es\"\n",
    "    test_es_path = f\"{base_path}/{language}/{test_folder}/data.es\"\n",
    "\n",
    "    train_src = load_lines(train_lang_path)\n",
    "    train_tgt = load_lines(train_es_path)\n",
    "\n",
    "    test_src = load_lines(test_lang_path)\n",
    "    test_tgt = load_lines(test_es_path)\n",
    "\n",
    "    # Crea datasets\n",
    "    train_dataset = Dataset.from_dict({\"input\": train_src, \"target\": train_tgt})\n",
    "    test_dataset = Dataset.from_dict({\"input\": test_src, \"target\": test_tgt})\n",
    "\n",
    "    return DatasetDict({\n",
    "        \"train\": train_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1751914996794,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "PmYZbWQ1kPpQ"
   },
   "outputs": [],
   "source": [
    "def invertir_input_target(example):\n",
    "    return {\n",
    "        \"input\": example[\"target\"],\n",
    "        \"target\": example[\"input\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "42ff61877490414eac5dae7623b10843",
      "c719c3092f7740b4bd3ea614a1e38144",
      "2911f8955ec740b29d0a63f5e2dbd9fb",
      "441ba7e9125f46ec9500b31b10697003",
      "b7fafb7f7221493684d915c80ec994e5",
      "28114dd004654d639dab41f2e8e8cc36",
      "b603fe43d26542b6a873d653bf5ccdf9",
      "dd16f7020eea4b5c9c601682a1422016",
      "a44151b1ea34474ebf2dbe7038f6585d",
      "9e7b9f9ea9474567b818a408c4058699",
      "fa43341040ac45c6b5e7158d9fac559d",
      "3e2329522c284693b3e2c13565e9134c",
      "241a83f28e3d4ccdbdb4fb7ae00ff81b",
      "8991a68dc9f846b99794db2b146d54fe",
      "a8a18b7619dd418ba2c42e4ddd8b1949",
      "f6d48558b56645f68f32cc0ec4f34703",
      "a36b774ead8140129961e5acec3d356e",
      "d724ee32366e42b28d09b83848f36cd1",
      "19a4905d7657407fb1f2daf02cf18b8d",
      "dc96201ee69c494fb7eebe11ecc9f400",
      "770966e325ca43daba41ed4729f252a7",
      "2ac34445964c41b5b1f9b42c2c547561"
     ]
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1751915805399,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "4l0xcZcOgsmx",
    "outputId": "d1e6fc7a-56c6-49c7-8a0d-6165b8b6592e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ff61877490414eac5dae7623b10843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2329522c284693b3e2c13565e9134c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "es_qum_dataset = generate_dataset(\"qum\", train_folder=\"test\", test_folder=\"dev\")\n",
    "es_qum_dataset = DatasetDict({\n",
    "    \"train\": es_qum_dataset[\"train\"].map(invertir_input_target),\n",
    "    \"test\": es_qum_dataset[\"test\"].map(invertir_input_target),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1751915262020,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "e-p1Rq94bTJL"
   },
   "outputs": [],
   "source": [
    "def generate_en_qum_dataset_from_files(\n",
    "    data_dir=\"./\",\n",
    "    base_path=\"mayanv/MayanV\",\n",
    "    language=\"qum\",\n",
    "    train_folder=\"test\",\n",
    "    test_folder=\"dev\",\n",
    "    lang=lang\n",
    "):\n",
    "    # Paths a los archivos .en\n",
    "    train_en_path = os.path.join(data_dir, f\"train.{lang}\")\n",
    "    test_en_path = os.path.join(data_dir, f\"test.{lang}\")\n",
    "\n",
    "    # Paths a los archivos .qum\n",
    "    train_qum_path = os.path.join(base_path, language, train_folder, \"data.qum\")\n",
    "    test_qum_path = os.path.join(base_path, language, test_folder, \"data.qum\")\n",
    "\n",
    "    # Carga las l√≠neas\n",
    "    train_en = load_lines(train_en_path)\n",
    "    test_en = load_lines(test_en_path)\n",
    "\n",
    "    train_qum = load_lines(train_qum_path)\n",
    "    test_qum = load_lines(test_qum_path)\n",
    "\n",
    "    # Validaci√≥n\n",
    "    assert len(train_en) == len(train_qum), f\"Train mismatch: {len(train_en)} vs {len(train_qum)}\"\n",
    "    assert len(test_en) == len(test_qum), f\"Test mismatch: {len(test_en)} vs {len(test_qum)}\"\n",
    "\n",
    "    # Combina en datasets Hugging Face\n",
    "    train_dataset = Dataset.from_dict({\"input\": train_en, \"target\": train_qum})\n",
    "    test_dataset = Dataset.from_dict({\"input\": test_en, \"target\": test_qum})\n",
    "\n",
    "    return DatasetDict({\n",
    "        \"train\": train_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    })\n",
    "\n",
    "\n",
    "en_qum_dataset = generate_en_qum_dataset_from_files(data_dir = '/content/IIC3697-Proyecto/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6AMhN2GZpNt"
   },
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1751915269430,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "4fo2s-t9Zozn"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    max_length = 128\n",
    "\n",
    "    inputs = finetune_tokenizer(\n",
    "        examples[\"input\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    targets = finetune_tokenizer(\n",
    "        examples[\"target\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def translate_text(model, tokenizer, text, src_lang, tgt_lang):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    forced_bos_id = tokenizer.convert_tokens_to_ids(tgt_lang)\n",
    "\n",
    "    # Detecta el dispositivo (GPU o CPU)\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Tokeniza y mueve a la misma device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Generaci√≥n\n",
    "    outputs = model.generate(**inputs, forced_bos_token_id=forced_bos_id)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "\n",
    "def build_and_save_split_en_only(split, model, tokenizer, output_dir):\n",
    "    input_path = os.path.join(output_dir, f\"{split}.{lang}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(input_path, \"w\", encoding=\"utf-8\") as f_en:\n",
    "        print(f\"üîÑ Traduciendo y guardando split '{split}' al {lang}...\\n\")\n",
    "\n",
    "        for example in tqdm(es_qum_dataset[split]):\n",
    "            es_text = example[\"input\"].replace(\"#qum#\", \"\").strip()\n",
    "\n",
    "            try:\n",
    "                en_text = translate_text(model, tokenizer, es_text, \"spa_Latn\", f\"{lang}_Latn\")\n",
    "                en_text = \"#qum# \" + en_text.strip()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error traduciendo: {es_text}\\n{e}\")\n",
    "                en_text = \"#qum#\"\n",
    "\n",
    "            f_en.write(en_text + \"\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Archivo '{split}.{lang}' guardado en {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5ukIdzqYhCo"
   },
   "source": [
    "## Crear dataset sint√©tico\n",
    "!SOLO EJECUTAR SI NO SE TIENE EL DATASET TODAVIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOjTDQjmYq8F"
   },
   "outputs": [],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "mid_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "mid_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "mid_tokenizer.src_lang = \"spa_Latn\"\n",
    "mid_forced_bos_id = mid_tokenizer.convert_tokens_to_ids(f\"{lang}_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9U4gFjfFYots"
   },
   "outputs": [],
   "source": [
    "output_dir = \"/content/drive/MyDrive/en_qum_dataset\"\n",
    "\n",
    "build_and_save_split_en_only(\"test\", mid_model, mid_tokenizer, output_dir)\n",
    "build_and_save_split_en_only(\"train\", mid_model, mid_tokenizer, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6y8Xh2RBAmS"
   },
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjWCp3bkc27u"
   },
   "source": [
    "### 1. Modelo con Finetuning Espa√±ol-Sipakapense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 9296,
     "status": "ok",
     "timestamp": 1751915819975,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "j0zKtLz_K7Uc"
   },
   "outputs": [],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "finetune_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "\n",
    "finetune_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Configurar LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "# Aplicar QLoRA\n",
    "finetune_model = get_peft_model(finetune_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1751915779464,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "-TAeIyJ4pOZM",
    "outputId": "2a29ff86-7f86-4f32-9232-d34dbcae9416"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M2M100ScaledWordEmbedding(256205, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A√±adir el token especial \"#qum#\" como marcador de idioma\n",
    "special_tokens_dict = {\"additional_special_tokens\": [\"#qum#\"]}\n",
    "finetune_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# Redimensionar embeddings del modelo para incluir el nuevo token\n",
    "finetune_model.resize_token_embeddings(len(finetune_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "7d32e0085b14465988de735ba5cb0e8c",
      "3cd55dbb46884a53ab253d0145e4633e",
      "d62b8459bb1a47abbaf45a166d96a1c0",
      "d8e2d4cfb91f4118a2956a05cd2b7e5b",
      "01e9e9638f54437d88bf3c8d74a4f66d",
      "fe1cdc9d8ba9481bbe8f9965500c38fb",
      "5b4bed5132e24507b177a587895b0bde",
      "fdceca5fe4484687ab9f074b284b3925",
      "79b6e38b238e433a942fc8ba1271964f",
      "8e9cc27f7906432ebf31bd3c6101cbd7",
      "cb18f9cefc6044989fc35525040930c0",
      "857e9ce764ee4a15996643a9e7c820f4",
      "e751ffcef7014424a13fe4fd23124b50",
      "2941010d336f421882b033d63a63592d",
      "681eb203166c4aae849757b96c2f95f0",
      "f4384493ee4a49e6bb7385777c2c9c2c",
      "1e40589252fe41ccac232f9c29b2779c",
      "728560280956437087deb916dceb6ade",
      "f89c363e4acb42d28e0b5b45621d80fc",
      "e5a7eeb6b1af48dfaa176a9efccf8ca4",
      "56e67293a0f4423fb90a8b0e15edc704",
      "540ac3f2a3604c9b8eb00f854d316bdd"
     ]
    },
    "executionInfo": {
     "elapsed": 1159,
     "status": "ok",
     "timestamp": 1751915834937,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "R2iPhpoQnSc2",
    "outputId": "8f643dfb-b37e-4885-f128-ba736ce50b05"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d32e0085b14465988de735ba5cb0e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857e9ce764ee4a15996643a9e7c820f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = es_qum_dataset[\"train\"].map(preprocess_function, batched=True)\n",
    "tokenized_test = es_qum_dataset[\"test\"].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "executionInfo": {
     "elapsed": 998391,
     "status": "ok",
     "timestamp": 1751916842597,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "aXgDM4lAnagN",
    "outputId": "97af9c59-6040-4ef5-ab17-9a91191fe226"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipython-input-28-1857230931.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 16:34, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.043700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.160100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>7.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>7.074900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>7.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>7.042800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>7.033100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./qlora_finetuned_qum_nllb/tokenizer_config.json',\n",
       " './qlora_finetuned_qum_nllb/special_tokens_map.json',\n",
       " './qlora_finetuned_qum_nllb/sentencepiece.bpe.model',\n",
       " './qlora_finetuned_qum_nllb/added_tokens.json',\n",
       " './qlora_finetuned_qum_nllb/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qlora_finetuned_qum_nllb\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=n_epochs,\n",
    "    learning_rate=2e-4,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_qlora\",\n",
    "    save_total_limit=2,\n",
    "    bf16=False,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetune_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=finetune_tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "finetune_model.save_pretrained(\"./qlora_finetuned_qum_nllb\")\n",
    "finetune_tokenizer.save_pretrained(\"./qlora_finetuned_qum_nllb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dazLUZlhKKHk"
   },
   "source": [
    "### 2. Modelo con Finetuning Italiano-Sipakapense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 8915,
     "status": "ok",
     "timestamp": 1751917157138,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "LEUkIjpj33ln"
   },
   "outputs": [],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "en_qum_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "en_qum_model = get_peft_model(base_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1751917157329,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "Stma1J90dTmA",
    "outputId": "7a2e7c52-ff79-40be-c3f1-6469f317555e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M2M100ScaledWordEmbedding(256205, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A√±adir el token especial \"#qum#\" como marcador de idioma\n",
    "special_tokens_dict = {\"additional_special_tokens\": [\"#qum#\"]}\n",
    "en_qum_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# Redimensionar embeddings del modelo para incluir el nuevo token\n",
    "en_qum_model.resize_token_embeddings(len(en_qum_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "43830efb29d046f88d76f7c247f275f2",
      "64a79a6ff75544a695b388f5b38f0c32",
      "8d469429fb964d5697d0d963ca117525",
      "dc89cecd54054c25aaa38c4473843207",
      "e871729cd4384915816c1e1116b3fca9",
      "d353f801e70b4b199fba89c839e945a6",
      "da6b6766117345f98d3dcfc4e84d33a0",
      "f6987e5029f947ad9d7286ce380d7e76",
      "b10d239bda5044b180289c3fdb331c7c",
      "d2fbbb82cb3b4d2ca35074f7829bbdf9",
      "4788c9535a5c4dddaec96d9f594bc8cb",
      "9548cc7961d04db3b9f648e46332b8f3",
      "9283b78a0a864d17bf1bf482bf35c061",
      "fad99b7b072a4492a7008f5390c3b52a",
      "8edc0d6a704a407ebb809a1a2cf2ebb2",
      "edc259bf10b9494c999e2b9c90e9d3f4",
      "93214f930c7f47b2b5beddfe5a66b2e7",
      "308d06b811994d8d80e8c7a4aca2b4e8",
      "75fb987bba4b4ad28eb514f080f75a9c",
      "7913e44046df4e92b4572bb7ea121aaa",
      "f3bc97469bbc47c9b84914e0bd9e228a",
      "4e737a157759486c9ed41011bec70bb1"
     ]
    },
    "executionInfo": {
     "elapsed": 1142,
     "status": "ok",
     "timestamp": 1751917158482,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "w1sEWghP4B7C",
    "outputId": "f8b93c2e-99cd-47bf-b1a3-63f8adfc9072"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43830efb29d046f88d76f7c247f275f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9548cc7961d04db3b9f648e46332b8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function_en_qum(examples):\n",
    "    max_length = 128\n",
    "    inputs = en_qum_tokenizer(examples[\"input\"], max_length=max_length, truncation=True, padding=True)\n",
    "    targets = en_qum_tokenizer(examples[\"target\"], max_length=max_length, truncation=True, padding=True)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_en_qum_train = en_qum_dataset[\"train\"].map(preprocess_function_en_qum, batched=True)\n",
    "tokenized_en_qum_test = en_qum_dataset[\"test\"].map(preprocess_function_en_qum, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1751917158507,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "mxivqDvt4GEf",
    "outputId": "f3724fc7-6fe2-4774-bfad-599507f23793"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "training_args_en_qum = TrainingArguments(\n",
    "    output_dir=\"./finetuned_en_qum_nllb\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=n_epochs,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_en_qum\",\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 869904,
     "status": "ok",
     "timestamp": 1751918028412,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "WWYUxQWm4IU_",
    "outputId": "b11a25e5-3a13-4987-bf87-8e6175b4315a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-33-1310942191.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_en_qum = Trainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 14:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>10.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>9.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>8.066800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>7.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>6.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>6.475500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>6.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>6.338900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.272700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>6.229300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>6.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>6.213900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>6.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>6.160600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>6.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>6.120900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>6.136000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1875, training_loss=6.807962646484375, metrics={'train_runtime': 869.2536, 'train_samples_per_second': 17.256, 'train_steps_per_second': 2.157, 'total_flos': 796271616000000.0, 'train_loss': 6.807962646484375, 'epoch': 15.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_en_qum = Trainer(\n",
    "    model=en_qum_model,\n",
    "    args=training_args_en_qum,\n",
    "    train_dataset=tokenized_en_qum_train,\n",
    "    eval_dataset=tokenized_en_qum_test,\n",
    "    tokenizer=en_qum_tokenizer,\n",
    ")\n",
    "\n",
    "trainer_en_qum.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc2QH1HJcuKn"
   },
   "source": [
    "## Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9jCIC05CCG_"
   },
   "source": [
    "### M√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "7d4014fd3caa46a782d8aadb4c7dc687",
      "b64a8fbb902843189dec008aa8733e47",
      "e2a62cb37bb645c2b768179d1f2a0118",
      "e2ebe1decb2f406291b545e4e217bd1a",
      "d0bf49adff584b70917323766d59e6e6",
      "ab567197328542d3a59b7ca13b131f00",
      "3213b4627e4148aeb4b76088d2a4cfc2",
      "a378c563c73e40e9bc0904930aed56f9",
      "4f463a2cbf244b128fe106af4ef1a24f",
      "b80c910d78b049d8a32aa5d64fffe47b",
      "be2247b0249a48caa08ddd3de5551d52",
      "47dcc80c219b4236adc8a3ce7f9961dc",
      "9dbfc3aa4f2c4c34a99d87ecdc7c3f5d",
      "a837bc778734463389325da23da922b5",
      "641087c5ce5a44939ed7c97c8263b5bc",
      "ce775155392f4b3b939c341f012ad43a",
      "af40e0e7cb9e41f4bd0bbdccb55aaf68",
      "0b547ab9c09c45d8a842425d9a2b5c05",
      "f64f763e8ed34362bd46a906ee3d0658",
      "dbd329743b7a44299d5ed813c324a1a5",
      "1fd1875b20a54ab39c2dca3b10315f36",
      "85ceecb04e604ce19c7697ce9565f450",
      "e600b02efd874bec882b23fe9071f469",
      "9d20bbd9d08b485eb9d63ad445d1a6ad",
      "214535660d154dfea328aa9426596e34",
      "7383d818c3884fa1b9244d92cdeaa94c",
      "511faa5b3bac469688ea224ef9181b71",
      "300d55c5078f48d18fcc62f08a0b9a4d",
      "84342a9b0405422c9492b0c167985e40",
      "6e9498657d9540b8b9a3f5b3ed63bfb7",
      "c584bea39dbc4dc8b8f1f8b2d8c6ebbf",
      "83244520ad1645729d6dfad6a6a0cc58",
      "ad4fc6b620fd44fb90a086aa9bed21ee",
      "ac063756affb4ca285f1128e79737800",
      "acdc22baa70b4458b5ed9101ca36a8ca",
      "29f950107e0241cd9be89e93593535f9",
      "e9a6b3f97630406f956062997d941ea0",
      "76af94c200f4484e997f87af07d1ad46",
      "efff9de136d043eb9cc5b57bed6d8c10",
      "dec766e77592430d84481675614e335f",
      "d3ffc752dad3413181663bce0ef86f9c",
      "36d04e07eb324454b2f0f9a93ebe08f1",
      "617c8b9f2eeb420399ad4ff9dde61d9b",
      "62999975073b482d9d73c2ed96383d0c",
      "5b00dbafa6284ac0a19925434ff9fcce",
      "ff25c58da04849eaa79aa02faa884638",
      "8f2ca6c1c3ff42d698f6713ef9883cb1",
      "3171c4f96de34e3f93fd9041994a03e6",
      "8f023d824f4e4064a47809ea94141500",
      "fe24b56e9ae4434e9a78eeb7a7be2edd",
      "1dd71591c0244454ba3caef22d17567a",
      "8565df8f14fe462ab00a3e08779130bb",
      "e656caaa4d21438dbbf17dedd916d30b",
      "1cd6d08cb6dc456da062ae91263c165c",
      "6a38a25110e44ab69c2cbe7f83f8821d"
     ]
    },
    "executionInfo": {
     "elapsed": 8363,
     "status": "ok",
     "timestamp": 1751918036794,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "YEoaaYAZCDnX",
    "outputId": "ffdb626f-5d3e-4c1c-f66e-280c0b887234"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4014fd3caa46a782d8aadb4c7dc687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dcc80c219b4236adc8a3ce7f9961dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e600b02efd874bec882b23fe9071f469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac063756affb4ca285f1128e79737800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b00dbafa6284ac0a19925434ff9fcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coKh9lECcw45"
   },
   "source": [
    "### Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1751918036825,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "m7IRRMdMiMtN"
   },
   "outputs": [],
   "source": [
    "origin_lang = \"deu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjB3SBkqn1JG"
   },
   "source": [
    "#### 1. Con Finetuning Espa√±ol-Sipakapense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 666474,
     "status": "ok",
     "timestamp": 1751918703303,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "8uBCVbR3obZG",
    "outputId": "3ba66528-b124-4717-fae2-27a936f34835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Traduciendo: deu ‚Üí Espa√±ol ‚Üí Sipakapense\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 321/321 [11:06<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_intermediate = []\n",
    "references_intermediate = []\n",
    "\n",
    "print(f\"\\nüîπ Traduciendo: {origin_lang} ‚Üí Espa√±ol ‚Üí Sipakapense\\n\")\n",
    "\n",
    "for item in tqdm(en_qum_dataset[\"test\"]):\n",
    "    input_text = item[\"input\"]\n",
    "    reference = item[\"target\"]\n",
    "\n",
    "    # Paso 1: origin_lang ‚Üí espa√±ol\n",
    "    inter = translate_text(finetune_model, finetune_tokenizer, input_text, f\"{origin_lang}_Latn\", \"spa_Latn\")\n",
    "\n",
    "    # Paso 2: espa√±ol ‚Üí \"Sipakapense\"\n",
    "    pred = translate_text(finetune_model, finetune_tokenizer, inter, \"spa_Latn\", \"qum\")\n",
    "\n",
    "    predictions_intermediate.append(pred)\n",
    "    references_intermediate.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1751918703350,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "qVv0v6pUvm-e"
   },
   "outputs": [],
   "source": [
    "clean_pred_intermediate = [pred.removeprefix(\"qum\").strip() for pred in predictions_intermediate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1751918703372,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "X2roPLoJoy2L",
    "outputId": "9d3abb62-d4f0-40bf-9f83-6c3d75ce0de8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplos Fine-Tuned ===\n",
      "\n",
      "> Entrada:     #qum# La moglie di Don Jesus usa solo il buon legno\n",
      "> Referencia:  wu rxqiil ta º xuux xaq utz laj si º kchuknik chre\n",
      "> Predicci√≥n:  ri wnaqik ri xb ºe ºk ºoq\n",
      "\n",
      "> Entrada:     #qum# Tutto il legno √®\n",
      "> Referencia:  Njeel ri xkarawa ºn xpoch ºik rech chenim xchaq ºjik\n",
      "> Predicci√≥n:  ri xk ºolik ri rq ºiij\n",
      "\n",
      "> Entrada:     #qum# Nel nostro paese non si parla pi√π la nostra lingua\n",
      "> Referencia:  Pri qtinmit qal chik kchkunsxik ri qyolb ºaal\n",
      "> Predicci√≥n:  xk ºolik ri ajk ºik ri rtz ºaq º\n",
      "\n",
      "> Entrada:     #qum# Lo studente sta imparando come\n",
      "> Referencia:  Ri ajtijnel tjin kirtijuuj c hemo rchkunsxik ri su º\n",
      "> Predicci√≥n:  ri ajk ºo ºj rech riij\n",
      "\n",
      "> Entrada:     #qum# La donna era abbracciata dal marito\n",
      "> Referencia:  Ri ixoq tz ºulmaj rum ri rchjiil\n",
      "> Predicci√≥n:  ri ajk ºal riij xtz ºaaj\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Ejemplos Fine-Tuned ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"> Entrada:     {en_qum_dataset['test'][i]['input']}\")\n",
    "    print(f\"> Referencia:  {en_qum_dataset['test'][i]['target']}\")\n",
    "    print(f\"> Predicci√≥n:  {clean_pred_intermediate[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4028,
     "status": "ok",
     "timestamp": 1751918707402,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "DcM-8kilozFz",
    "outputId": "1f761b3c-f487-490a-9f06-6379592f860e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== M√©tricas BLEU ===\n",
      "BLEU-1: 13.20\n",
      "BLEU-2: 0.00\n",
      "BLEU-3: 0.00\n",
      "BLEU-4: 0.00\n",
      "BLEU total: 0.00\n",
      "\n",
      "=== M√©tricas ROUGE ===\n",
      "ROUGE-1:   14.15\n",
      "ROUGE-2:   0.42\n",
      "ROUGE-L:   13.71\n",
      "ROUGE-Lsum:13.68\n",
      "\n",
      "=== Otras M√©tricas ===\n",
      "METEOR:     7.48\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=clean_pred_intermediate, references=[[ref] for ref in references_intermediate])\n",
    "\n",
    "print(\"\\n=== M√©tricas BLEU ===\")\n",
    "print(f\"BLEU-1: {bleu_score['precisions'][0]*100:.2f}\")\n",
    "print(f\"BLEU-2: {bleu_score['precisions'][1]*100:.2f}\")\n",
    "print(f\"BLEU-3: {bleu_score['precisions'][2]*100:.2f}\")\n",
    "print(f\"BLEU-4: {bleu_score['precisions'][3]*100:.2f}\")\n",
    "print(f\"BLEU total: {bleu_score['bleu']*100:.2f}\")\n",
    "\n",
    "rouge_score = rouge.compute(predictions=clean_pred_intermediate, references=references_intermediate)\n",
    "\n",
    "print(\"\\n=== M√©tricas ROUGE ===\")\n",
    "print(f\"ROUGE-1:   {rouge_score['rouge1']*100:.2f}\")\n",
    "print(f\"ROUGE-2:   {rouge_score['rouge2']*100:.2f}\")\n",
    "print(f\"ROUGE-L:   {rouge_score['rougeL']*100:.2f}\")\n",
    "print(f\"ROUGE-Lsum:{rouge_score['rougeLsum']*100:.2f}\")\n",
    "\n",
    "meteor_score = meteor.compute(predictions=clean_pred_intermediate, references=references_intermediate)\n",
    "\n",
    "print(\"\\n=== Otras M√©tricas ===\")\n",
    "print(f\"METEOR:     {meteor_score['meteor']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1751918707414,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "-MTsr6mJBWrm",
    "outputId": "954133ec-acc5-47cb-ab83-e884ff7eb5ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'results_es_qum_finetune_intermediate.tsv'\n"
     ]
    }
   ],
   "source": [
    "with open(f\"results_{lang}_qum_finetune_intermediate.tsv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"input\", \"reference\", \"prediction\"])\n",
    "\n",
    "    for example, pred, ref in zip(es_qum_dataset[\"test\"], predictions_intermediate, references_intermediate):\n",
    "        writer.writerow([example[\"input\"], ref, pred])\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en 'results_es_qum_finetune_intermediate.tsv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_UFY-dToFsb"
   },
   "source": [
    "#### 2. Con Finetuning Italiano-Sipakapense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20694,
     "status": "ok",
     "timestamp": 1751918728107,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "RCLhcjT-aUtA",
    "outputId": "f0e3cefa-7370-4319-825b-ffbb00f3c129"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./qlora_finetuned_model_deu_quc_nllb/tokenizer_config.json',\n",
       " './qlora_finetuned_model_deu_quc_nllb/special_tokens_map.json',\n",
       " './qlora_finetuned_model_deu_quc_nllb/sentencepiece.bpe.model',\n",
       " './qlora_finetuned_model_deu_quc_nllb/added_tokens.json',\n",
       " './qlora_finetuned_model_deu_quc_nllb/tokenizer.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_model = en_qum_model\n",
    "finetune_tokenizer = en_qum_tokenizer\n",
    "\n",
    "finetune_model.save_pretrained(\"./qlora_finetuned_model_deu_quc_nllb\")\n",
    "finetune_tokenizer.save_pretrained(\"./qlora_finetuned_model_deu_quc_nllb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281974,
     "status": "ok",
     "timestamp": 1751919010064,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "c0UrnNGqobuo",
    "outputId": "a264e9a7-9622-43d7-ac8b-a1811b5d39d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Traduciendo: deu ‚Üí Sipakapense\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 321/321 [04:41<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_direct = []\n",
    "references_direct = []\n",
    "\n",
    "print(f\"\\nüîπ Traduciendo: {origin_lang} ‚Üí Sipakapense\\n\")\n",
    "\n",
    "for item in tqdm(en_qum_dataset[\"test\"]):\n",
    "    input_text = item[\"input\"]\n",
    "    reference = item[\"target\"]\n",
    "\n",
    "    pred = translate_text(finetune_model, finetune_tokenizer, input_text, f\"{origin_lang}_Latn\", \"qum\")\n",
    "\n",
    "    predictions_direct.append(pred)\n",
    "    references_direct.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1751919010068,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "chF42cMCu0k2"
   },
   "outputs": [],
   "source": [
    "clean_pred_direct = [pred.removeprefix(\"qum\").strip() for pred in predictions_direct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1751919010153,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "WGGj_XKctmn9",
    "outputId": "d0947495-fbc8-4b63-fca7-8261d2146c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplos Fine-Tuned ===\n",
      "\n",
      "> Entrada:     #qum# La moglie di Don Jesus usa solo il buon legno\n",
      "> Referencia:  wu rxqiil ta º xuux xaq utz laj si º kchuknik chre\n",
      "> Predicci√≥n:  ri ajb ºal\n",
      "\n",
      "> Entrada:     #qum# Tutto il legno √®\n",
      "> Referencia:  Njeel ri xkarawa ºn xpoch ºik rech chenim xchaq ºjik\n",
      "> Predicci√≥n:  xb ºal xb ºo ºl chu ºb ºal\n",
      "\n",
      "> Entrada:     #qum# Nel nostro paese non si parla pi√π la nostra lingua\n",
      "> Referencia:  Pri qtinmit qal chik kchkunsxik ri qyolb ºaal\n",
      "> Predicci√≥n:  xtz ºal k ºi ºb ºal\n",
      "\n",
      "> Entrada:     #qum# Lo studente sta imparando come\n",
      "> Referencia:  Ri ajtijnel tjin kirtijuuj c hemo rchkunsxik ri su º\n",
      "> Predicci√≥n:  ri x ºo ºb ºal xb ºo ºb ºal\n",
      "\n",
      "> Entrada:     #qum# La donna era abbracciata dal marito\n",
      "> Referencia:  Ri ixoq tz ºulmaj rum ri rchjiil\n",
      "> Predicci√≥n:  ri ri x ºoojb ºik ri xb ºal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Ejemplos Fine-Tuned ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"> Entrada:     {en_qum_dataset['test'][i]['input']}\")\n",
    "    print(f\"> Referencia:  {en_qum_dataset['test'][i]['target']}\")\n",
    "    print(f\"> Predicci√≥n:  {clean_pred_direct[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1751919010737,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "uNuiAUOytvUu",
    "outputId": "09470cbc-f195-41a2-b250-78703925ed92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== M√©tricas BLEU ===\n",
      "BLEU-1: 10.40\n",
      "BLEU-2: 0.00\n",
      "BLEU-3: 0.00\n",
      "BLEU-4: 0.00\n",
      "BLEU total: 0.00\n",
      "\n",
      "=== M√©tricas ROUGE ===\n",
      "ROUGE-1:   8.90\n",
      "ROUGE-2:   0.09\n",
      "ROUGE-L:   8.49\n",
      "ROUGE-Lsum:8.50\n",
      "\n",
      "=== Otras M√©tricas ===\n",
      "METEOR:     3.60\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=clean_pred_direct, references=[[ref] for ref in references_direct])\n",
    "\n",
    "print(\"\\n=== M√©tricas BLEU ===\")\n",
    "print(f\"BLEU-1: {bleu_score['precisions'][0]*100:.2f}\")\n",
    "print(f\"BLEU-2: {bleu_score['precisions'][1]*100:.2f}\")\n",
    "print(f\"BLEU-3: {bleu_score['precisions'][2]*100:.2f}\")\n",
    "print(f\"BLEU-4: {bleu_score['precisions'][3]*100:.2f}\")\n",
    "print(f\"BLEU total: {bleu_score['bleu']*100:.2f}\")\n",
    "\n",
    "rouge_score = rouge.compute(predictions=clean_pred_direct, references=references_direct)\n",
    "\n",
    "print(\"\\n=== M√©tricas ROUGE ===\")\n",
    "print(f\"ROUGE-1:   {rouge_score['rouge1']*100:.2f}\")\n",
    "print(f\"ROUGE-2:   {rouge_score['rouge2']*100:.2f}\")\n",
    "print(f\"ROUGE-L:   {rouge_score['rougeL']*100:.2f}\")\n",
    "print(f\"ROUGE-Lsum:{rouge_score['rougeLsum']*100:.2f}\")\n",
    "\n",
    "meteor_score = meteor.compute(predictions=clean_pred_direct, references=references_direct)\n",
    "\n",
    "print(\"\\n=== Otras M√©tricas ===\")\n",
    "print(f\"METEOR:     {meteor_score['meteor']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1751919010793,
     "user": {
      "displayName": "Vittorio Salvatore",
      "userId": "03642540342691197752"
     },
     "user_tz": 240
    },
    "id": "2o0_ZKITBrRf",
    "outputId": "f6516120-8d36-485b-e2bf-849ccae00587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'results_it_qum_finetune_direct.tsv'\n"
     ]
    }
   ],
   "source": [
    "filename = f\"results_{lang}_qum_finetune_direct.tsv\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"input\", \"reference\", \"prediction\"])\n",
    "\n",
    "    for example, pred, ref in zip(es_qum_dataset[\"test\"], predictions_direct, references_direct):\n",
    "        writer.writerow([example[\"input\"], ref, pred])\n",
    "\n",
    "print(f\"‚úÖ Resultados guardados en '{filename}'\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
